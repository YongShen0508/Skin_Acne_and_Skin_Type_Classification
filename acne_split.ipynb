{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed00903c-e705-42e5-a926-fa8f864fc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571db780-59a2-4e98-a6d8-0b067995612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset split successfully! Original dataset retained, and train/test sets are unique.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset\"\n",
    "train_path = \"dataset/train\"\n",
    "test_path = \"dataset/test\"\n",
    "\n",
    "# Ensure train and test directories exist\n",
    "for folder in [train_path, test_path]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Iterate through Level_0, Level_1, Level_2\n",
    "for category in [\"Level_0\", \"Level_1\", \"Level_2\"]:\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "\n",
    "    # Skip if it's not a directory\n",
    "    if not os.path.isdir(category_path):\n",
    "        continue  \n",
    "\n",
    "    # Collect all image files\n",
    "    images = [f for f in os.listdir(category_path) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "\n",
    "    # Shuffle for randomness\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Split 80% train, 20% test\n",
    "    split_index = int(0.8 * len(images))\n",
    "    train_images, test_images = images[:split_index], images[split_index:]\n",
    "\n",
    "    # Create category subfolders in train/test\n",
    "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_path, category), exist_ok=True)\n",
    "\n",
    "    # Copy images to train/test (Keeping original dataset)\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(category_path, img), os.path.join(train_path, category, img))\n",
    "\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(category_path, img), os.path.join(test_path, category, img))\n",
    "\n",
    "    # Ensure images are unique in train/test by removing them from the original folder\n",
    "    for img in images:\n",
    "        os.remove(os.path.join(category_path, img))\n",
    "\n",
    "print(\"✅ Dataset split successfully! Original dataset retained, and train/test sets are unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73bad03-4bb3-4504-9829-c55875d7aabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 798 images belonging to 3 classes.\n",
      "Found 201 images belonging to 3 classes.\n",
      "Class labels: ['Level_0', 'Level_1', 'Level_2']\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "train_dir = \"dataset/train\"\n",
    "test_dir = \"dataset/test\"\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\" Resize the image to (128,128) without altering other properties \"\"\"\n",
    "    img = np.array(img, dtype=np.float32)  # Ensure float32\n",
    "    img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_CUBIC)  # High-quality resizing\n",
    "    return img  # Return unchanged, only resized image\n",
    "\n",
    "\n",
    "# Define ImageDataGenerator (without additional augmentation)\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_image)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_image)\n",
    "\n",
    "# Load images from directories\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),  # Already resized by preprocessing_function\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Get class labels \n",
    "class_labels = list(train_data.class_indices.keys())\n",
    "print(\"Class labels:\", class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0d9185-275f-4fab-a868-66f6fc0f09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "Level_0: 309 images\n",
      "Level_1: 378 images\n",
      "Level_2: 111 images\n",
      "\n",
      "Test Dataset:\n",
      "Level_0: 78 images\n",
      "Level_1: 95 images\n",
      "Level_2: 28 images\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Count images per class in training data\n",
    "train_class_counts = Counter(train_data.labels)\n",
    "test_class_counts = Counter(test_data.labels)\n",
    "\n",
    "# Map indices to class names\n",
    "class_labels = list(train_data.class_indices.keys())\n",
    "\n",
    "# Print results\n",
    "print(\"Train Dataset:\")\n",
    "for i, count in train_class_counts.items():\n",
    "    print(f\"{class_labels[i]}: {count} images\")\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "for i, count in test_class_counts.items():\n",
    "    print(f\"{class_labels[i]}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034632e1-d1f9-4a9b-8363-59a941a65eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
